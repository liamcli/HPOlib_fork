{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import fnmatch\n",
    "import glob\n",
    "import numpy\n",
    "import pickle\n",
    "import copy\n",
    "from numpy import genfromtxt,min,mean,max,std,array,shape,nanmin\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "open_ml_ids= [2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,18,20,21,22,23,24,26,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,47,48,49,50,52,53,54,55,57,58,59,60,2065,2073,2074,2075,2078,2079,3022]\n",
    "#Need to rerun for nvb\n",
    "open_ml_ids.remove(7)\n",
    "#Not enough arms trained on full train set for nvb_hyperband\n",
    "open_ml_ids.remove(6)\n",
    "open_ml_ids.remove(26)\n",
    "open_ml_ids.remove(34)\n",
    "open_ml_ids.remove(38)\n",
    "open_ml_ids.remove(2078)\n",
    "#Do not converge within 10 mins\n",
    "open_ml_ids.remove(2065)\n",
    "open_ml_ids.remove(2075)\n",
    "#dataset_ids=[item for sublist in open_ml_ids for item in sublist]\n",
    "\n",
    "datasets_keep = open_ml_ids\n",
    "len(datasets_keep)\n",
    "dataset_max_train_size=pickle.load(open('../dataset_max_train_size.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_avg(errors,test_errors,durations,intervals,dataset,normalization=None):\n",
    "    min_errors=[]\n",
    "    min_test_errors=[]\n",
    "    sum_durations=[]\n",
    "    interval_errors=[]\n",
    "    interval_test_errors=[]\n",
    "    for t in range(len(errors)):\n",
    "        err=errors[t]\n",
    "        test_err=test_errors[t]\n",
    "        temp=numpy.ones(len(err))\n",
    "        temp_test=numpy.ones(len(err))\n",
    "        temp[0]=numpy.nanmin([1,err[0]])\n",
    "        temp_test[0]=numpy.nanmin([1,test_err[0]])\n",
    "        for iter in range(1,len(err)):\n",
    "            if numpy.nanmin([err[iter],temp[iter-1]])<temp[iter-1]:\n",
    "                temp[iter]=err[iter]\n",
    "                temp_test[iter]=test_err[iter]\n",
    "            else:\n",
    "                temp[iter]=temp[iter-1]\n",
    "                temp_test[iter]=temp_test[iter-1]                \n",
    "        min_errors.append(temp)\n",
    "        min_test_errors.append(temp_test)\n",
    "    for dur in durations:\n",
    "        temp = [sum(dur[0:(i+1)]) for i in range(len(dur))]\n",
    "        if normalization is not None:\n",
    "            temp=numpy.array(temp)/normalization[dataset]\n",
    "        sum_durations.append(temp)\n",
    "    for trial in range(len(sum_durations)):\n",
    "        min_err=min_errors[trial]\n",
    "        min_test_err=min_test_errors[trial]\n",
    "        sum_dur=sum_durations[trial]\n",
    "        temp=[]\n",
    "        temp_test=[]\n",
    "        for t in intervals:\n",
    "            indices=[ n for n,i in enumerate(sum_dur) if i<=t ]\n",
    "            if len(indices)>0:\n",
    "                temp.append(min_err[indices[-1]])\n",
    "                temp_test.append(min_test_err[indices[-1]])\n",
    "            else:\n",
    "                temp.append(1)\n",
    "                temp_test.append(1)\n",
    "        interval_errors.append(temp)\n",
    "        interval_test_errors.append(temp_test)\n",
    "    avg_interval_err = numpy.mean(interval_errors,axis=0)\n",
    "    avg_interval_test_err = numpy.mean(interval_test_errors,axis=0)\n",
    "    std_interval_err = numpy.std(interval_errors,axis=0)\n",
    "    std_interval_test_err = numpy.std(interval_test_errors,axis=0)\n",
    "    return len(errors), avg_interval_err, std_interval_err, avg_interval_test_err, std_interval_test_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_avg_iters(errors,test_errors):\n",
    "    min_errors=[]\n",
    "    min_test_errors=[]\n",
    "    sum_durations=[]\n",
    "    interval_errors=[]\n",
    "    interval_test_errors=[]\n",
    "    for t in range(len(errors)):\n",
    "        err=errors[t]\n",
    "        test_err=test_errors[t]\n",
    "        temp=numpy.ones(len(err))\n",
    "        temp_test=numpy.ones(len(err))\n",
    "        temp[0]=numpy.nanmin([1,err[0]])\n",
    "        temp_test[0]=numpy.nanmin([1,test_err[0]])\n",
    "        for iter in range(1,len(err)):\n",
    "            if numpy.nanmin([err[iter],temp[iter-1]])<temp[iter-1]:\n",
    "                temp[iter]=err[iter]\n",
    "                temp_test[iter]=test_err[iter]\n",
    "            else:\n",
    "                temp[iter]=temp[iter-1]\n",
    "                temp_test[iter]=temp_test[iter-1]                \n",
    "        min_errors.append(temp)\n",
    "        min_test_errors.append(temp_test)\n",
    "    min_iters=numpy.min([len(t) for t in min_errors])\n",
    "    avg_interval_err = numpy.mean([t[:min_iters] for t in min_errors],axis=0)\n",
    "    avg_interval_test_err = numpy.mean([t[:min_iters] for t in min_test_errors],axis=0)\n",
    "    std_interval_err = numpy.std([t[:min_iters] for t in min_errors],axis=0)\n",
    "    std_interval_test_err = numpy.std([t[:min_iters] for t in min_test_errors],axis=0)\n",
    "    return len(errors), avg_interval_err, std_interval_err, avg_interval_test_err, std_interval_test_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_percentiles(errors,test_errors,durations,intervals):\n",
    "    min_errors=[]\n",
    "    min_test_errors=[]\n",
    "    sum_durations=[]\n",
    "    interval_errors=[]\n",
    "    interval_test_errors=[]\n",
    "    for t in range(len(errors)):\n",
    "        err=errors[t]\n",
    "        test_err=test_errors[t]\n",
    "        temp=numpy.ones(len(err))\n",
    "        temp_test=numpy.ones(len(err))\n",
    "        temp[0]=numpy.nanmin([1,err[0]])\n",
    "        temp_test[0]=numpy.nanmin([1,test_err[0]])\n",
    "        for iter in range(1,len(err)):\n",
    "            if numpy.nanmin([err[iter],temp[iter-1]])<temp[iter-1]:\n",
    "                temp[iter]=err[iter]\n",
    "                temp_test[iter]=test_err[iter]\n",
    "            else:\n",
    "                temp[iter]=temp[iter-1]\n",
    "                temp_test[iter]=temp_test[iter-1]                \n",
    "        min_errors.append(temp)\n",
    "        min_test_errors.append(temp_test)\n",
    "    for dur in durations:\n",
    "        temp = [sum(dur[0:(i+1)]) for i in range(len(dur))]\n",
    "        sum_durations.append(temp)\n",
    "    for trial in range(len(sum_durations)):\n",
    "        min_err=min_errors[trial]\n",
    "        min_test_err=min_test_errors[trial]\n",
    "        sum_dur=sum_durations[trial]\n",
    "        temp=[]\n",
    "        temp_test=[]\n",
    "        for t in intervals:\n",
    "            indices=[ n for n,i in enumerate(sum_dur) if i<=t ]\n",
    "            if len(indices)>0:\n",
    "                temp.append(min_err[indices[-1]])\n",
    "                temp_test.append(min_test_err[indices[-1]])\n",
    "            else:\n",
    "                temp.append(1)\n",
    "                temp_test.append(1)\n",
    "        interval_errors.append(temp)\n",
    "        interval_test_errors.append(temp_test)\n",
    "    err_median = numpy.median(interval_errors,axis=0)\n",
    "    test_err_median = numpy.median(interval_test_errors,axis=0)\n",
    "    err_high_qtr = numpy.percentile(interval_errors,75,axis=0,interpolation='midpoint')\n",
    "    test_err_high_qtr = numpy.percentile(interval_test_errors,75,axis=0,interpolation='midpoint')\n",
    "    err_low_qtr = numpy.percentile(interval_errors,25,axis=0,interpolation='midpoint')\n",
    "    test_err_low_qtr = numpy.percentile(interval_test_errors,25,axis=0,interpolation='midpoint')\n",
    "    return len(errors), err_median,test_err_median,err_high_qtr,test_err_high_qtr,err_low_qtr,test_err_low_qtr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_count(durations,intervals):\n",
    "    sum_durations=[]\n",
    "    interval_count=[]\n",
    "\n",
    "    for dur in durations:\n",
    "        temp = [sum(dur[0:(i+1)]) for i in range(len(dur))]\n",
    "        sum_durations.append(temp)\n",
    "    for trial in range(len(sum_durations)):\n",
    "        sum_dur=sum_durations[trial]\n",
    "        temp=[]\n",
    "        for t in intervals:\n",
    "            indices=[ n for n,i in enumerate(sum_dur) if i<=t ]\n",
    "            if len(indices)>0:\n",
    "                temp.append(len(indices))\n",
    "            else:\n",
    "                temp.append(0)\n",
    "        interval_count.append(temp)\n",
    "    avg_interval_count = numpy.mean(interval_count,axis=0)\n",
    "    avg_interval_min = numpy.nanmin(interval_count,axis=0)\n",
    "    avg_interval_max = numpy.nanmax(interval_count,axis=0)\n",
    "    \n",
    "    return avg_interval_count,avg_interval_min,avg_interval_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_pkl(files,smac_init=False):\n",
    "    errors = []\n",
    "    test_errors = []\n",
    "    durations=[]\n",
    "    \n",
    "    for f in files:\n",
    "        data=pickle.load(open(f,'rb'))\n",
    "        if len(data['cv_endtime'])>0:\n",
    "            error=[i['result'] for i in data['trials']]\n",
    "            errors.append(error)\n",
    "            test_error=[i['test_error'] for i in data['trials']]\n",
    "            test_errors.append(test_error)\n",
    "            duration=[data['cv_endtime'][0]-data['starttime'][0]]\n",
    "            for t in range(1,len(data['cv_endtime'])):\n",
    "                duration.append(data['cv_endtime'][t]-data['cv_endtime'][t-1])\n",
    "            durations.append(duration)\n",
    "    \n",
    "    return_results=[errors,test_errors,durations]\n",
    "    if smac_init:\n",
    "        return return_results,[[t[0] for t in errors],[t[0] for t in test_errors],[t[0] for t in durations]]\n",
    "    return return_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#only include results on full training set\n",
    "def parse_nvb_pkl(dataset,files,train_size_dictionary,smac_init=None):\n",
    "    errors = []\n",
    "    test_errors = []\n",
    "    durations=[]\n",
    "    \n",
    "    for f in files:\n",
    "        data=pickle.load(open(f,'rb'))\n",
    "        max_train_size=train_size_dictionary[dataset]\n",
    "        full_train_iters=numpy.where(numpy.asarray([t['train_size'] for t in data['trials']])==max_train_size)[0]\n",
    "        if len(full_train_iters)<5:\n",
    "            print f + ' has fewer than 5 arms trained on max sample sizes'\n",
    "        if len(data['cv_endtime'])>0:\n",
    "            error=[i['result'] for i in data['trials'] if i['train_size']==max_train_size]\n",
    "            errors.append(error)\n",
    "            test_error=[i['test_error'] for i in data['trials'] if i['train_size']==max_train_size]\n",
    "            test_errors.append(test_error)\n",
    "            duration=[data['cv_endtime'][full_train_iters[0]]-data['starttime'][0]]\n",
    "            for t in range(1,len(full_train_iters)):\n",
    "                duration.append(data['cv_endtime'][full_train_iters[t]]-data['cv_endtime'][full_train_iters[t-1]])\n",
    "            durations.append(duration)\n",
    "    \n",
    "    if smac_init is not None:\n",
    "        for t in range(len(errors)):\n",
    "            errors[t].insert(0,smac_init[0][t])\n",
    "            test_errors[t].insert(0,smac_init[1][t])\n",
    "            durations[t].insert(0,smac_init[2][t])\n",
    "    return errors,test_errors,durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#combine 3 random runs for 3 hours\n",
    "def parse_random_pkl(files,smac_init=None):\n",
    "    errors = []\n",
    "    long_errors = []\n",
    "    long_test_errors = []\n",
    "    long_durations = []\n",
    "    test_errors = []\n",
    "    durations=[]\n",
    "    \n",
    "    for f in files:\n",
    "        data=pickle.load(open(f,'rb'))\n",
    "        if len(data['cv_endtime'])>0:\n",
    "            error=[i['result'] for i in data['trials']]\n",
    "            test_error=[i['test_error'] for i in data['trials']]\n",
    "            duration=[data['cv_endtime'][0]-data['starttime'][0]]\n",
    "            for t in range(1,len(data['cv_endtime'])):\n",
    "                duration.append(data['cv_endtime'][t]-data['cv_endtime'][t-1])\n",
    "            if len(error)>len(duration):\n",
    "                error.pop()\n",
    "                test_error.pop()\n",
    "            errors.append(error)\n",
    "            test_errors.append(test_error)\n",
    "            durations.append(duration)   \n",
    "    for i in range(len(errors)/3):\n",
    "        long_errors.append(errors[3*i]+errors[3*i+1]+errors[3*i+2])\n",
    "        long_test_errors.append(test_errors[3*i]+test_errors[3*i+1]+test_errors[3*i+2])\n",
    "        long_durations.append(durations[3*i]+durations[3*i+1]+durations[3*i+2])\n",
    "    errors=long_errors\n",
    "    test_errors=long_test_errors\n",
    "    durations=long_durations\n",
    "    \n",
    "    if smac_init is not None:\n",
    "        for t in range(len(errors)):\n",
    "            errors[t].insert(0,smac_init[0][t])\n",
    "            test_errors[t].insert(0,smac_init[1][t])\n",
    "            durations[t].insert(0,smac_init[2][t])\n",
    "    \n",
    "    return errors,test_errors,durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "18\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "35\n",
      "36\n",
      "37\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "2073\n",
      "2074\n",
      "2079\n",
      "3022\n"
     ]
    }
   ],
   "source": [
    "#results={}\n",
    "intervals=range(30,3601,30)\n",
    "intervals_long=range(30,10801,30)\n",
    "results={}\n",
    "smac_init={}\n",
    "for dataset in datasets_keep:\n",
    "    print dataset\n",
    "    smac_files= glob.glob('../open_ml_'+str(dataset)+'_*smac*/*smac_2_06*.pkl')\n",
    "    hyperopt_files=glob.glob('../open_ml_'+str(dataset)+'_*hyperopt*/*hyperopt_august2013_mod.pkl')\n",
    "    random_files=glob.glob('../open_ml_'+str(dataset)+'_*random*/*random_hyperopt_august2013_mod.pkl')\n",
    "    hyperopt_files=[h for h in hyperopt_files if h not in random_files]\n",
    "    nvb_files=glob.glob('../open_ml_'+str(dataset)+'_*nvb_hyperband*/*nvb_hyperband.pkl')\n",
    "    smac_files.sort()\n",
    "    hyperopt_files.sort()\n",
    "    random_files.sort()\n",
    "    nvb_files.sort()\n",
    "    results[dataset]={}\n",
    "    #data=pickle.load(open(hyperopt_files[0],'rb'))\n",
    "    #dataset_max_train_size[dataset]=numpy.nanmax([t['train_size'] for t in data['trials']])\n",
    "    if len(smac_files)>0:\n",
    "        dataset_results,dataset_init=parse_pkl(smac_files,True)\n",
    "        results[dataset]['smac']=dataset_results\n",
    "        smac_init[dataset]=dataset_init\n",
    "    if len(hyperopt_files) > 0:\n",
    "        results[dataset]['hyperopt']=parse_pkl(hyperopt_files)\n",
    "    if len(random_files)>0:\n",
    "        results[dataset]['random']=parse_random_pkl(random_files,dataset_init)\n",
    "    if len(nvb_files)>0:\n",
    "        results[dataset]['nvb']=parse_nvb_pkl(dataset,nvb_files,dataset_max_train_size,dataset_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename='../all_results_smac_init.pkl'\n",
    "pickle.dump(results,open(filename,'wb'))\n",
    "#filename='dataset_max_train_size.pkl'\n",
    "#pickle.dump(dataset_max_train_size,open(filename,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results=pickle.load(open('./all_results.pkl','rb'))\n",
    "#Calculate random average train time\n",
    "dataset_avg_time={}\n",
    "for d in results.keys():\n",
    "    sum_dur=results[d]['random'][2]\n",
    "    durations = []\n",
    "    for t in range(len(sum_dur)):\n",
    "        durations=durations + sum_dur[t]\n",
    "    dataset_avg_time[d]=numpy.nanmean(durations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Calculate normalized interval errors\n",
    "normalize=False\n",
    "if normalize:\n",
    "    max_iters=7200/int(numpy.min([dataset_avg_time[d] for d in dataset_avg_time.keys()]))\n",
    "    intervals=range(1,max_iters+1)\n",
    "    long_intervals=range(1,3*max_iters+3)\n",
    "else:\n",
    "    intervals=range(30,7201,30)\n",
    "    long_intervals=range(30,21601,30)\n",
    "condensed_results={}\n",
    "searchers=results[2].keys()\n",
    "for d in results.keys():\n",
    "    condensed_results[d]={}\n",
    "    for s in searchers:\n",
    "        if s=='random':\n",
    "            condensed_results[d][s]=calculate_avg(results[d][s][0],results[d][s][1],results[d][s][2],long_intervals,d)    \n",
    "        else:\n",
    "            condensed_results[d][s]=calculate_avg(results[d][s][0],results[d][s][1],results[d][s][2],intervals,d)    \n",
    "        #Results append rf_baseline\n",
    "    trials=condensed_results[d]['smac'][0]\n",
    "    val_error = [numpy.mean([t[0] for t in results[d]['smac'][0]])]*len(intervals)\n",
    "    test_error = [numpy.mean([t[0] for t in results[d]['smac'][1]])]*len(intervals)\n",
    "    variance=[0]*len(intervals)\n",
    "    condensed_results[d]['rf_baseline']=[trial,val_error,variance,test_error,variance]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename='./all_results_condensed.pkl'\n",
    "pickle.dump(condensed_results,open(filename,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, array([ 0.4123188,  0.2735507,  0.2731884, ...,  0.2507247,  0.2507247,\n",
       "         0.2507247]), array([ 0.29415205,  0.02442626,  0.02415334, ...,  0.00720992,\n",
       "         0.00720992,  0.00720992]), array([ 0.4391304,  0.2869565,  0.2942029, ...,  0.2927535,  0.2927535,\n",
       "         0.2927535]), array([ 0.28679908,  0.06666643,  0.0590655 , ...,  0.04797956,\n",
       "         0.04797956,  0.04797956]))"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Script to find out last update\n",
    "argmins=[]\n",
    "times=[]\n",
    "for d in results.keys():\n",
    "    data=results[d]['random'][0]\n",
    "    indices = [numpy.argmin(t) for t in data]\n",
    "    argmins = argmins+[numpy.argmin(t) for t in data]\n",
    "    times=times+ [numpy.sum(results[d]['random'][2][t][0:indices[t]])/dataset_avg_time[d] for t in range(len(data))]\n",
    "max(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "################################### ALL LINES BELOW NO LONGER USED ########################################\n",
    "################################### ALL LINES BELOW NO LONGER USED ########################################\n",
    "################################### ALL LINES BELOW NO LONGER USED ########################################\n",
    "################################### ALL LINES BELOW NO LONGER USED ########################################\n",
    "to_fix=[]\n",
    "\n",
    "for d in datasets_keep:\n",
    "    for s in ['smac','hyperopt','random','nvb']:\n",
    "        if s not in results[d]:\n",
    "            to_fix.append([d,s,0])\n",
    "        elif results[d][s][0] < 10:\n",
    "            to_fix.append([d,s,results[d][s][0]])\n",
    "        elif nanmin(results[d][s][1])==1:\n",
    "            to_fix.append([d,s,1])\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def chart_error_iter(datasets, validation,interval_size):\n",
    "    searchers=['smac','hyperopt','random','nvb']\n",
    "    if validation==True:\n",
    "        ind = 1\n",
    "        title='Best Validation Error for Dataset '\n",
    "        filename='individual_charts_val_error_iter.pdf'\n",
    "    else:\n",
    "        ind = 3\n",
    "        title='Test Error Corresponding to Best Validation Error for Dataset '\n",
    "        filename='individual_charts_test_error_iter.pdf'\n",
    "    pdf_file=PdfPages(filename)\n",
    "    for d in datasets:\n",
    "        x = range(interval_size-1,len(results[d]['smac'][ind]),interval_size)\n",
    "        indices=x\n",
    "        plt.plot(x,[results[d]['smac'][ind][i] for i in indices],color='r',label='SMAC')\n",
    "        x = range(interval_size-1,len(results[d]['hyperopt'][ind]),interval_size)\n",
    "        indices=x\n",
    "        plt.plot(x,[results[d]['hyperopt'][ind][i] for i in indices],color='b',label='Hyperopt/TPE')\n",
    "        x = range(interval_size-1,len(results[d]['nvb'][ind]),interval_size)\n",
    "        indices=x\n",
    "        plt.plot(x,[results[d]['nvb'][ind][i] for i in indices],color='y',label='nvb_batch')\n",
    "        x = range(interval_size-1,len(results[d]['random'][ind]),interval_size)\n",
    "        indices=x\n",
    "        plt.plot(x,[results[d]['random'][ind][i] for i in indices],color='g',label='Random')\n",
    "        plt.xlabel('# of Arms Trained on Full Training Data')\n",
    "        plt.title(title+str(d))\n",
    "        plt.legend(loc=1)\n",
    "        pdf_file.savefig()\n",
    "        plt.close()\n",
    "    pdf_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chart_error_iter(full_datasets,True,1)\n",
    "chart_error_iter(full_datasets,False,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "myfile=open(\"to_fix.csv\",'wb')\n",
    "wr=csv.writer(myfile)\n",
    "for i in to_fix:\n",
    "    wr.writerow(i)\n",
    "myfile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "to_fix_id=numpy.unique([t[0] for t in to_fix])\n",
    "full_datasets=[d for d in datasets_keep if d not in to_fix_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trial_iters=[]\n",
    "for d in full_datasets:\n",
    "    temp=[results[d]['smac'][0],results[d]['hyperopt'][0],results[d]['random'][0],results[d]['nvb'][0]]\n",
    "    trial_iters.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def chart_error(datasets, validation,indices,errorbars=False):\n",
    "    if validation==True:\n",
    "        ind = 1\n",
    "        title='Best Validation Error for Dataset '\n",
    "        filename='individual_charts_val_error.pdf'\n",
    "    else:\n",
    "        ind = 3\n",
    "        title='Test Error Corresponding to Best Validation Error for Dataset '\n",
    "        filename='individual_charts_test_error.pdf'\n",
    "    pdf_file=PdfPages(filename)\n",
    "    x=[intervals[i] for i in indices]\n",
    "    for d in datasets:\n",
    "        if errorbars:\n",
    "            plt.errorbar(x,[results[d]['smac'][ind][i] for i in indices],yerr=[results[d]['smac'][ind+1][i] for i in indices],marker='o',color='r',markeredgecolor='r',markerfacecolor='None',label='SMAC')\n",
    "            plt.errorbar(x,[results[d]['hyperopt'][ind][i] for i in indices],yerr=[results[d]['hyperopt'][ind+1][i] for i in indices],marker='x',color='b',label='Hyperopt/TPE')\n",
    "            plt.errorbar(x,[results[d]['nvb'][ind][i] for i in indices],yerr=[results[d]['nvb'][ind+1][i] for i in indices],color='y',marker='^',markeredgecolor='y',markerfacecolor='None',label='nvb_batch')\n",
    "            plt.errorbar(x,[results[d]['random'][ind][i] for i in indices],yerr=[results[d]['random'][ind+1][i] for i in indices],marker='+',color='g',label='Random')\n",
    "        else:\n",
    "            plt.errorbar(x,[results[d]['smac'][ind][i] for i in indices],marker='o',color='r',markeredgecolor='r',markerfacecolor='None',label='SMAC')\n",
    "            plt.errorbar(x,[results[d]['hyperopt'][ind][i] for i in indices],marker='x',color='b',label='Hyperopt/TPE')\n",
    "            plt.errorbar(x,[results[d]['nvb'][ind][i] for i in indices],color='y',marker='^',markeredgecolor='y',markerfacecolor='None',label='nvb_batch')\n",
    "            plt.errorbar(x,[results[d]['random'][ind][i] for i in indices],marker='+',color='g',label='Random')\n",
    "        plt.xlabel('Time (s)')\n",
    "        plt.title(title+str(d))\n",
    "        plt.legend(loc=1)\n",
    "        pdf_file.savefig()\n",
    "        plt.close()\n",
    "    pdf_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chart_error(full_datasets,True,range(120),False)\n",
    "chart_error(full_datasets,False,range(120),False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def chart_error_perc(datasets, validation,interval_size):\n",
    "    searchers=['smac','hyperopt','random','nvb']\n",
    "    if validation==True:\n",
    "        ind = 0\n",
    "        title='Median Best Validation Error for Dataset '\n",
    "        filename='individual_charts_val_error_perc.pdf'\n",
    "    else:\n",
    "        ind = 1\n",
    "        title='Median Test Error Corresponding to Best Validation Error for Dataset '\n",
    "        filename='individual_charts_test_error_perc.pdf'\n",
    "    pdf_file=PdfPages(filename)\n",
    "    for d in datasets:\n",
    "        x = range(interval_size-1,len(results[d]['smac'][ind+1]),interval_size)\n",
    "        indices=x\n",
    "        plt.errorbar(x,[results[d]['smac'][ind][i] for i in indices],marker='o',color='r',markeredgecolor='r',markerfacecolor='None',label='SMAC')\n",
    "        plt.errorbar(x,[results[d]['hyperopt'][ind][i] for i in indices],marker='x',color='b',label='Hyperopt/TPE')\n",
    "        plt.errorbar(x,[results[d]['nvb'][ind][i] for i in indices],color='y',marker='^',markeredgecolor='y',markerfacecolor='None',label='nvb_batch')\n",
    "        plt.errorbar(x,[results[d]['random'][ind][i] for i in indices],marker='+',color='g',label='Random')\n",
    "        plt.title(title+str(d))\n",
    "        plt.legend(loc=1)\n",
    "        pdf_file.savefig()\n",
    "        plt.close()\n",
    "    pdf_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chart_error_perc(full_datasets,False,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data_rel=[]\n",
    "data_abs=[]\n",
    "index_avg=3\n",
    "for dataset in full_datasets:\n",
    "    n_iters=len(intervals)\n",
    "    iter_errors = [[results[dataset]['smac'][index_avg][i],results[dataset]['hyperopt'][index_avg][i],results[dataset]['random'][index_avg][i],results[dataset]['nvb'][index_avg][i]] for i in range(n_iters)]\n",
    "    iter_min = [min(i) for i in iter_errors]\n",
    "    #iter_rel = [[j/iter_min[i] for j in iter_errors[i]] for i in range(n_iters-10)]\n",
    "    iter_abs = [[j-iter_min[i] for j in iter_errors[i]] for i in range(n_iters)]\n",
    "    for k in range(n_iters):\n",
    "        ind2=2*k+1\n",
    "        ind3=3*k+2\n",
    "        if ind2 < 2*(n_iters):\n",
    "            iter_abs[k].append(results[dataset]['random'][index_avg][2*k+1]-iter_min[k])\n",
    "        #else:\n",
    "        #    iter_abs[k].append(nanmin(results[dataset]['random'][index_avg])-iter_min[k])\n",
    "        if ind3 < 3*(n_iters):\n",
    "            iter_abs[k].append(results[dataset]['random'][index_avg][3*k+2]-iter_min[k])\n",
    "        #else:\n",
    "        #    iter_abs[k].append(nanmin(results[dataset]['random'][index_avg])-iter_min[k])\n",
    "    #data_rel.append(iter_rel)\n",
    "    data_abs.append(iter_abs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data_rel=numpy.array(data_rel)\n",
    "data_abs=numpy.array(data_abs)\n",
    "#data_rel_avg=mean(data_rel,axis=0)\n",
    "data_abs_avg=mean(data_abs,axis=0)    \n",
    "data_abs_std=std(data_abs,axis=0)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "title='Test'\n",
    "pdf_file=PdfPages('aggregate_charts_test.pdf')\n",
    "iters=intervals\n",
    "results_index=3\n",
    "\n",
    "#3plt.figure(figsize=(11,8.5))\n",
    "#plt.plot(iters,data_rel_avg[:,0],'r--',label='SMAC')\n",
    "#plt.plot(iters,data_rel_avg[:,1],'bs',label='Hyperopt/TPE')\n",
    "#plt.plot(iters,data_rel_avg[:,2],'g^',label='Random')\n",
    "#plt.legend(loc=2)\n",
    "#plt.title('Relative Performance Versus Best Validation Error Averaged Over 51 Datasets')\n",
    "#pdf_file.savefig()\n",
    "#plt.close()\n",
    "\n",
    "plt.figure(figsize=(11,8.5))\n",
    "#plt.ylim(-0.005,0.01)\n",
    "plt.errorbar(iters[9:n_iters:10],data_abs_avg[9:n_iters:10,0],yerr=data_abs_std[9:n_iters:10,0],color='r',linestyle='--',label='SMAC')\n",
    "plt.errorbar(iters[9:n_iters:10],data_abs_avg[9:n_iters:10,1],yerr=data_abs_std[9:n_iters:10,1],color='b',marker='s',label='Hyperopt/TPE')\n",
    "plt.errorbar(iters[9:n_iters:10],data_abs_avg[9:n_iters:10,2],yerr=data_abs_std[9:n_iters:10,2],color='g',marker='^',label='Random')\n",
    "plt.errorbar(iters[9:n_iters:10],data_abs_avg[9:n_iters:10,3],yerr=data_abs_std[9:n_iters:10,3],color='y',marker='o',label='nvb_batch')\n",
    "plt.errorbar(iters[9:n_iters:10],data_abs_avg[9:n_iters:10,4],color='g',marker='o',label='Random 2x Speedup')\n",
    "plt.errorbar(iters[9:n_iters:10],data_abs_avg[9:n_iters:10,5],color='g',marker='*',label='Random 3x Speedup')\n",
    "plt.title('Absolute Difference from Best '+title+' Error Averaged Over 47 Datasets')\n",
    "plt.legend()\n",
    "plt.xlabel('Time (s)')\n",
    "pdf_file.savefig()\n",
    "plt.close()\n",
    "\n",
    "ind = numpy.arange(len(full_datasets))  # the x locations for the groups\n",
    "width = 0.18       # the width of the bars\n",
    "\n",
    "for t in [30, 60, 90, 120]:\n",
    "    fig, ax = plt.subplots(figsize=(11,8.5))\n",
    "    rects1 = ax.bar(ind,[results[key]['smac'][results_index][t-1] for key in full_datasets], width, color='r')\n",
    "    rects2 = ax.bar(ind + width, [results[key]['hyperopt'][results_index][t-1] for key in full_datasets], width, color='b')\n",
    "    rects3 = ax.bar(ind + width +width, [results[key]['random'][results_index][t-1] for key in full_datasets], width, color='g')\n",
    "    rects4 = ax.bar(ind + width +width+width, [results[key]['nvb'][results_index][t-1] for key in full_datasets], width, color='y')\n",
    "\n",
    "    # add some text for labels, title and axes ticks\n",
    "    ax.set_ylabel('Datasets')\n",
    "    ax.set_title('Average '+title+' Error After '+str(t*30/60)+' Minutes')\n",
    "    plt.xlim(0,len(full_datasets)+1)\n",
    "    ax.legend((rects1[0], rects2[0],rects3[0],rects4[0]), ('SMAC','TPE','Random','nvb_batch'),loc=2)\n",
    "    #plt.tight_layout()\n",
    "    pdf_file.savefig()\n",
    "    plt.close()\n",
    "\n",
    "pdf_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[4, 'smac', 9],\n",
       " [8, 'smac', 9],\n",
       " [34, 'smac', 8],\n",
       " [37, 'smac', 8],\n",
       " [40, 'smac', 8],\n",
       " [42, 'smac', 8],\n",
       " [47, 'smac', 6],\n",
       " [50, 'smac', 8],\n",
       " [52, 'smac', 9],\n",
       " [59, 'smac', 7]]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 718.0,\n",
       " 3: 2556.0,\n",
       " 4: 45.0,\n",
       " 5: 361.0,\n",
       " 6: 16000.0,\n",
       " 8: 276.0,\n",
       " 9: 164.0,\n",
       " 10: 118.0,\n",
       " 11: 500.0,\n",
       " 12: 1600.0,\n",
       " 13: 228.0,\n",
       " 14: 1600.0,\n",
       " 15: 559.0,\n",
       " 16: 1600.0,\n",
       " 18: 1600.0,\n",
       " 20: 1600.0,\n",
       " 21: 1382.0,\n",
       " 22: 1600.0,\n",
       " 23: 1178.0,\n",
       " 24: 6499.0,\n",
       " 26: 10368.0,\n",
       " 28: 4496.0,\n",
       " 29: 552.0,\n",
       " 30: 4378.0,\n",
       " 31: 800.0,\n",
       " 32: 8793.0,\n",
       " 33: 432.0,\n",
       " 34: 72.0,\n",
       " 35: 292.0,\n",
       " 36: 1848.0,\n",
       " 37: 614.0,\n",
       " 38: 268.0,\n",
       " 39: 166.0,\n",
       " 40: 171.0,\n",
       " 41: 546.0,\n",
       " 42: 244.0,\n",
       " 43: 3680.0,\n",
       " 47: 120.0,\n",
       " 48: 242.0,\n",
       " 49: 766.0,\n",
       " 50: 235.0,\n",
       " 52: 216.0,\n",
       " 53: 676.0,\n",
       " 54: 124.0,\n",
       " 55: 348.0,\n",
       " 57: 280.0,\n",
       " 58: 4000.0,\n",
       " 59: 120.0,\n",
       " 60: 80.0,\n",
       " 2073: 1187.0,\n",
       " 2074: 5144.0,\n",
       " 2078: 329.0,\n",
       " 2079: 588.0,\n",
       " 3022: 792.0}"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
